{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x25bb1efdaf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model import HAN_Model\n",
    "from data import IMDB_Data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import config as argumentparser\n",
    "config = argumentparser.ArgumentParser()\n",
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as argumentparser\n",
    "config = argumentparser.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.cuda and torch.cuda.is_available():  # 是否使用gpu\n",
    "    torch.cuda.set_device(config.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available() # 查看gpu是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 280593\n",
      "10000 280593\n",
      "20000 280593\n",
      "30000 280593\n",
      "40000 280593\n",
      "50000 280593\n",
      "60000 280593\n",
      "70000 280593\n",
      "80000 280593\n",
      "90000 280593\n",
      "100000 280593\n",
      "110000 280593\n",
      "120000 280593\n",
      "130000 280593\n",
      "140000 280593\n",
      "150000 280593\n",
      "160000 280593\n",
      "170000 280593\n",
      "180000 280593\n",
      "190000 280593\n",
      "200000 280593\n",
      "210000 280593\n",
      "220000 280593\n",
      "230000 280593\n",
      "240000 280593\n",
      "250000 280593\n",
      "260000 280593\n",
      "270000 280593\n",
      "280000 280593\n"
     ]
    }
   ],
   "source": [
    "# 导入训练集\n",
    "training_set = IMDB_Data(\"imdb-train.txt.ss\",min_count=config.min_count,\n",
    "                         max_sentence_length = config.max_sentence_length,batch_size=config.batch_size,is_pretrain=False)\n",
    "training_iter = torch.utils.data.DataLoader(dataset=training_set,\n",
    "                                            batch_size=config.batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 34029\n",
      "10000 34029\n",
      "20000 34029\n",
      "30000 34029\n"
     ]
    }
   ],
   "source": [
    "# 导入测试集\n",
    "test_set = IMDB_Data(\"imdb-test.txt.ss\",min_count=config.min_count,word2id=training_set.word2id,\n",
    "                         max_sentence_length = config.max_sentence_length,batch_size=config.batch_size)\n",
    "test_iter = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                        batch_size=config.batch_size,\n",
    "                                        shuffle=False,\n",
    "                                        num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HAN_Model(vocab_size=len(training_set.word2id),\n",
    "                  embedding_size=config.embedding_size,\n",
    "                  gru_size = config.gru_size,class_num=config.class_num,weights=training_set.weight,is_pretrain=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.cuda and torch.cuda.is_available(): # 如果使用gpu，将模型送进gpu\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # 这里会做softmax\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "loss = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_result(data_iter,data_set):\n",
    "    # 生成测试结果\n",
    "    model.eval()\n",
    "    true_sample_num = 0\n",
    "    for data, label in data_iter:\n",
    "        if config.cuda and torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "        else:\n",
    "            data = torch.autograd.Variable(data).long()\n",
    "        if config.cuda and torch.cuda.is_available():\n",
    "            out = model(data, gpu=True)\n",
    "        else:\n",
    "            out = model(data)\n",
    "        true_sample_num += np.sum((torch.argmax(out, 1) == label).cpu().numpy())\n",
    "    acc = true_sample_num / data_set.__len__()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                   | 3/4385 [00:49<23:57:46, 19.69s/it, loss=2.19]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a30bc3d16ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprocess_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss_now\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_test_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Program Files\\anconda\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--> 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Program Files\\anconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(config.epoch):\n",
    "    model.train()\n",
    "    process_bar = tqdm(training_iter)\n",
    "    for data, label in process_bar:\n",
    "        if config.cuda and torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "        else:\n",
    "            data = torch.autograd.Variable(data).long()\n",
    "        label = torch.autograd.Variable(label).squeeze()\n",
    "        if config.cuda and torch.cuda.is_available():\n",
    "            out = model(data,gpu=True)\n",
    "        else:\n",
    "            out = model(data)\n",
    "        loss_now = criterion(out, autograd.Variable(label.long()))\n",
    "        if loss == -1:\n",
    "            loss = loss_now.data.item()\n",
    "        else:\n",
    "            loss = 0.95*loss+0.05*loss_now.data.item()\n",
    "        process_bar.set_postfix(loss=loss_now.data.item())\n",
    "        process_bar.update()\n",
    "        optimizer.zero_grad()\n",
    "        loss_now.backward()\n",
    "        optimizer.step()\n",
    "    test_acc = get_test_result(test_iter, test_set)\n",
    "    print(\"The test acc is: %.5f\" % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
