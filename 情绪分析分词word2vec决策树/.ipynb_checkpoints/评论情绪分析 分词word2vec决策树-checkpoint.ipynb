{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本分词 Word2Vec 方法 决策树分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本情绪分析\n",
    "可能会出现的情绪有：高兴、兴奋、激动、没感觉、失落、压抑、紧张、疑惑等。\n",
    "而在自然语言处理的世界里，我们尚且达不到如此细小的分类。所以，往往在针对文本进行情绪分析时，只处理两种情绪状态：积极和消极。\n",
    "\n",
    "当然，上面提到的计算机无法处理更细分的情绪类别其实并不准确。因为，算法原则上是能够区分更多的情绪类别，\n",
    "关键在于我们需要提供一个人工标注过的复杂情绪训练集，而这是非常难做到的。所以，目前我们在进行情绪分析时，只处理积极和消极两种状态。\n",
    "\n",
    "## 基于词典的方法\n",
    "目前，针对文本情绪分析的方法有两种，一种基于词典，另一种基于机器学习方法。首先，我们来叙述一下基于词典的文本情绪分析原理。\n",
    "\n",
    "基于词典的情绪分析是非常简单和易于理解的一种方法。概括来讲，我们首先有一个人工标注好的词典。词典中的每一个此都对应这消极或积极的标签。词典举例如下：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-07T14:36:06.614487Z",
     "start_time": "2019-10-07T14:36:06.607522Z"
    }
   },
   "source": [
    "词语\t标签\n",
    "很好\t积极\n",
    "不好\t消极\n",
    "高兴\t积极\n",
    "难受\t消极\n",
    "爱你\t积极\n",
    "讨厌\t消极\n",
    "……\t……\n",
    "然后，这个词典可能有上万条或者几十万条，当然是越多越好。有了词典之后，我们就可以开始进行文本情绪分析了。\n",
    "\n",
    "现在，我们收到一条用户评论：\n",
    "\n",
    "这门课程很好啊！\n",
    "\n",
    "然后，我们可以对这句话进行分词。分词结果如下：\n",
    "\n",
    "['这门', '课程', '很', '好', '啊', '！']\n",
    "\n",
    "接下来，我们拿分好的词依次去匹配词典。匹配的方法很简单：\n",
    "\n",
    "如果词典中存在该词且为积极标签，那么我们记 +1+1;\n",
    "如果词典中存在该词且为消极标签，那么我们记 -1−1;\n",
    "如果词典中不存在该词，我们记 00。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "匹配完一个句子之后，我们就可以计算整个句子的得分。总得分 >0>0 表示该句子情绪为积极，总得分小于零代表该句子为消极，总得分 =0=0 表示无法判断情绪。通过词典进行情绪分析的方法很简单，但缺点也很明显。\n",
    "**我们往往需要一个很大的词典，且不断更新。**\n",
    "这对人力物力都是极大的考验。\n",
    "\n",
    "除此之外，该方法还有无法通过扩充词典解决的情绪判断问题。例如，当我们人类在判断一句话的清晰时，我们会往往更偏向于从整体把握（语言环境），尤其是在乎一些**语气助词**对情绪的影响。而基于词典进行情绪分析的方法就做不到这一点，将句子拆成词，就会影响句子的整体情绪表达。\n",
    " \n",
    "目前，针对中文做情绪标注的词典少之又少。比较常用的有：\n",
    "\n",
    "台湾大学 NTUSD 情绪词典。\n",
    "《知网》情绪分析用 词语集。\n",
    "以《知网》情绪词典举例，它包含有 5 个文件，分别列述了正面与负面的情绪词语以及程度词汇。\n",
    "\n",
    "“正面情感”词语，如：爱，赞赏，快乐，感同身受，好奇，喝彩，魂牵梦萦，嘉许 ...\n",
    "“负面情感”词语，如：哀伤，半信半疑，鄙视，不满意，不是滋味儿，后悔，大失所望 ...\n",
    "“正面评价”词语，如：不可或缺，部优，才高八斗，沉鱼落雁，催人奋进，动听，对劲儿 ...\n",
    "“负面评价”词语，如：丑，苦，超标，华而不实，荒凉，混浊，畸轻畸重，价高，空洞无物 ...\n",
    "“程度级别”词语，\n",
    "“主张”词语\n",
    "由于上面介绍的这种简单的词典对比方法准确率并不高，所以本实验不会通过这种方法来实现用户评论情绪分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于词袋或 Word2Vec 的方法\n",
    "词袋模型\n",
    "除了基于词典对评论进行情绪分析，我们还有一种方法称之为词袋模型。词袋不再将一句话看做是单个词汇构成，而是当作一个 1 \\times N1×N 的向量。举个例子，我们现在有两句话需要处理，分别是：\n",
    "\n",
    "我爱你，我非常爱你。 我喜欢你，我非常喜欢你。\n",
    "\n",
    "我们针对这两句话进行分词之后，去重处理为一个词袋：\n",
    "\n",
    "['我', '爱', '喜欢', '你', '非常']\n",
    "\n",
    "然后，根据词袋，我们对原句子进行向量转换。其中，向量的长度 N 为词袋的长度，而向量中每一个数值依次为词袋中的词出现在该句子中的次数。\n",
    "\n",
    "我爱你，我非常爱你。 → [2, 2, 0, 2, 1]\n",
    "\n",
    "我喜欢你，我非常喜欢你。 → [2, 0, 2, 2, 1]\n",
    "\n",
    "有了词袋，有了已经人工标注好的句子，就组成了我们的训练数据。再根据机器学习方法来构建分类预测模型。从而判断新输入句子的情绪。\n",
    "\n",
    "你会发现，**词袋模型和我们之前提到的独热编码非常相似。其实这里就是将之前独热编码里的词变成了句子而已。**\n",
    "\n",
    "词袋模型固然比简单的词典对比方法更好，但独热编码无法度量上下文之间的距离，也就无法结合上下文进行情绪判断。下面，我们介绍一种词向量的 Word2Vec 处理方法，就会很好地克服这个缺点。\n",
    "\n",
    "Word2Vec\n",
    "Word2Vec，故名思意就是将句子转换为向量，也就是词向量。Word2Vec 最早由 Google 在 2013 年开源，它是由浅层神经网络组成的词向量转换模型。\n",
    "\n",
    "Word2Vec 的输入一般为规模庞大的语料库，输出为向量空间。Word2Vec 的特点在于，**语料库中的每个词都对应了向量空间中的一个向量，拥有上下文关系的词，映射到向量空间中的距离会更加接近。**\n",
    "\n",
    "Word2Vec 的主要结构是 **CBOW（Continuous Bag-of-Words Model）模型和 Skip-gram（Continuous Skip-gram）**模型结合在一起。简单来讲，二者都是想通过上下文得到一个词出现的概率。\n",
    "\n",
    "**CBOW 模型通过一个词的上下文（各 N 个词）预测当前词。而 Skip-gram 则恰好相反，他是用一个词预测其上下文，得到了当前词上下文的很多样本，因此可用于更大的数据集。**\n",
    "\n",
    "CBOW（N=2）和 Skip-gram 的结构如下图所示：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CBOW skip-gram.png](https://doc.shiyanlou.com/document-uid214893labid3472timestamp1505724363811.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中 w(t)w(t) 表示当前的词汇，而 w(t−n)w(t−n)，w(t+n)w(t+n) 等则用来表示上下文词汇。\n",
    "\n",
    "实验楼用户评论情绪分析\n",
    "为了保证良好的准确度，本次实验我们选用了 Word2Vec 结合决策树的文本情绪分析方法。\n",
    "首先，我们需要使用 Word2Vec 来建立向量空间，之后再使用决策树训练文本情绪分类模型。\n",
    "\n",
    "由于我们未人工针对实验楼评论进行语料库标注，所以这里需要选择其他的已标注语料库进行模型训练。\n",
    "这里，我们选用了网友苏剑林提供的语料库。该语料库整合了书籍、计算机等 7 个领域的评论数据。\n",
    "\n",
    "你可以通过下面链接下载本次实验所需要的数据集："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://labfile.oss.aliyuncs.com/courses/764/data_09.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "其中，消极情绪文本 neg.xls 共有 10428 行。\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.read_excel(\"data_09/data/neg.xls\", header=None).head()\n",
    "\n",
    "积极情绪文本 pos.xls 共有 10679 行。\n",
    "\n",
    "pd.read_excel(\"data_09/data/pos.xls\", header=None).head()\n",
    "\n",
    "实验楼用户评论文本 comments.csv 共有 12377 行。\n",
    "\n",
    "pd.read_csv(\"data_09/comments.csv\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "14px",
    "right": "20px",
    "top": "556px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
